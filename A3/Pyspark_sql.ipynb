{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "692de198-9691-4d96-a864-74fb5ea5a001",
   "metadata": {},
   "source": [
    "## Section B - Working with DataFrames and SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4490962f-7ccb-42f1-9924-54ff5858bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8183e15d-6afe-4104-a412-4c08b6599391",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/02/20 19:26:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# creating a spark session.\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.250:7077\") \\\n",
    "        .appName(\"Koushik_A3_sql\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.shuffleTracking.enabled\",True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", False)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.executor.cores\",2)\\\n",
    "        .config(\"spark.driver.port\",9999)\\\n",
    "        .config(\"spark.blockManager.port\",10005)\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# RDD API\n",
    "spark_context = spark_session.sparkContext\n",
    "\n",
    "spark_context.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3554ad82-9dc9-4fb1-828c-6a853293cca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/pyspark/sql/context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.context.SQLContext at 0x7f6475345820>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext = SQLContext(spark_session.sparkContext)\n",
    "sqlContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a3d782-8ba7-4523-a7aa-945d7f8ae43f",
   "metadata": {},
   "source": [
    "### Question B.1 Load the CSV file from HDFS, and call show() to verify the data is loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c60ca654-6971-4ba5-8962-a39bd3a9784b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Loading csv file from hdfs and storing it into a variable.\n",
    "df= sqlContext.read.csv('hdfs://192.168.2.250:9000/parking-citations.csv',header='true', inferSchema='true').cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f0593f5-389e-48e1-a9b8-20ea0c40f399",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:=====================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+--------------------+-----+------+--------------+---------------------+-----------+---------+---------+------------------+-----------------+----------------------+\n",
      "|Ticket number|         Issue Date|Issue time|Meter Id|Marked Time|RP State Plate|Plate Expiry Date| VIN|Make|Body Style|Color|            Location|Route|Agency|Violation code|Violation Description|Fine amount| Latitude|Longitude|Agency Description|Color Description|Body Style Description|\n",
      "+-------------+-------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+--------------------+-----+------+--------------+---------------------+-----------+---------+---------+------------------+-----------------+----------------------+\n",
      "|   1103341116|2015-12-21 00:00:00|    1251.0|    NULL|       NULL|            CA|         200304.0|NULL|HOND|        PA|   GY|     13147 WELBY WAY|01521|   1.0|        4000A1|   NO EVIDENCE OF REG|       50.0|  99999.0|  99999.0|              NULL|             NULL|                  NULL|\n",
      "|   1103700150|2015-12-21 00:00:00|    1435.0|    NULL|       NULL|            CA|         201512.0|NULL| GMC|        VN|   WH|       525 S MAIN ST| 1C51|   1.0|        4000A1|   NO EVIDENCE OF REG|       50.0|  99999.0|  99999.0|              NULL|             NULL|                  NULL|\n",
      "|   1104803000|2015-12-21 00:00:00|    2055.0|    NULL|       NULL|            CA|         201503.0|NULL|NISS|        PA|   BK|       200 WORLD WAY|  2R2|   2.0|          8939|           WHITE CURB|       58.0|6439997.9|1802686.4|              NULL|             NULL|                  NULL|\n",
      "|   1104820732|2015-12-26 00:00:00|    1515.0|    NULL|       NULL|            CA|             NULL|NULL|ACUR|        PA|   WH|       100 WORLD WAY| 2F11|   2.0|           000|               17104h|       NULL|6440041.1|1802686.2|              NULL|             NULL|                  NULL|\n",
      "|   1105461453|2015-09-15 00:00:00|     115.0|    NULL|       NULL|            CA|         200316.0|NULL|CHEV|        PA|   BK|  GEORGIA ST/OLYMPIC|1FB70|   1.0|         8069A| NO STOPPING/STANDING|       93.0|  99999.0|  99999.0|              NULL|             NULL|                  NULL|\n",
      "|   1106226590|2015-09-15 00:00:00|      19.0|    NULL|       NULL|            CA|         201507.0|NULL|CHEV|        VN|   GY|  SAN PEDRO S/O BOYD|1A35W|   1.0|        4000A1|   NO EVIDENCE OF REG|       50.0|  99999.0|  99999.0|              NULL|             NULL|                  NULL|\n",
      "|   1106500452|2015-12-17 00:00:00|    1710.0|    NULL|       NULL|            CA|         201605.0|NULL|MAZD|        PA|   BL|     SUNSET/ALVARADO|00217|   1.0|          8070| PARK IN GRID LOCK ZN|      163.0|  99999.0|  99999.0|              NULL|             NULL|                  NULL|\n",
      "|   1106500463|2015-12-17 00:00:00|    1710.0|    NULL|       NULL|            CA|         201602.0|NULL|TOYO|        PA|   BK|     SUNSET/ALVARADO|00217|   1.0|          8070| PARK IN GRID LOCK ZN|      163.0|  99999.0|  99999.0|              NULL|             NULL|                  NULL|\n",
      "|   1106506402|2015-12-22 00:00:00|     945.0|    NULL|       NULL|            CA|         201605.0|NULL|CHEV|        PA|   BR|      721 S WESTLAKE| 2A75|   1.0|        8069AA|     NO STOP/STAND AM|       93.0|  99999.0|  99999.0|              NULL|             NULL|                  NULL|\n",
      "|   1106506413|2015-12-22 00:00:00|    1100.0|    NULL|       NULL|            CA|         201701.0|NULL|NISS|        PA|   SI|     1159 HUNTLEY DR| 2A75|   1.0|        8069AA|     NO STOP/STAND AM|       93.0|  99999.0|  99999.0|              NULL|             NULL|                  NULL|\n",
      "|   1106506424|2015-12-22 00:00:00|    1100.0|    NULL|       NULL|            CA|         201511.0|NULL|FORD|        TR|   WH|     1159 HUNTLEY DR| 2A75|   1.0|        8069AA|     NO STOP/STAND AM|       93.0|  99999.0|  99999.0|              NULL|             NULL|                  NULL|\n",
      "|   1106506435|2015-12-22 00:00:00|    1105.0|    NULL|       NULL|            CA|         201701.0|NULL|CHRY|        PA|   GO|     1159 HUNTLEY DR| 2A75|   1.0|        8069AA|     NO STOP/STAND AM|       93.0|  99999.0|  99999.0|              NULL|             NULL|                  NULL|\n",
      "|   1106506446|2015-12-22 00:00:00|    1110.0|    NULL|       NULL|            CA|         201511.0|NULL| BMW|        PA|   BK|      1200 W MIRAMAR| 2A75|   1.0|        4000A1|   NO EVIDENCE OF REG|       50.0|  99999.0|  99999.0|              NULL|             NULL|                  NULL|\n",
      "|   1106549754|2015-12-15 00:00:00|     825.0|    NULL|       NULL|            CA|         201607.0|NULL|PTRB|        TR|   BK|           4TH/STATE| CM96|   1.0|         8069A| NO STOPPING/STANDING|       93.0|  99999.0|  99999.0|              NULL|             NULL|                  NULL|\n",
      "|   1107179581|2015-12-27 00:00:00|    1055.0|    NULL|       NULL|            CA|         201605.0|NULL|TOYO|        PA|   BK|3100 N HOLLYRIDGE DR| NULL|  54.0|         8058L|         PREF PARKING|       68.0|  99999.0|  99999.0|              NULL|             NULL|                  NULL|\n",
      "|   1107179592|2015-12-27 00:00:00|    1200.0|    NULL|       NULL|            CA|         201602.0|NULL|MBNZ|        PA|   BK|   3115 N BERENDO DR| NULL|  54.0|         8058L|         PREF PARKING|       68.0|  99999.0|  99999.0|              NULL|             NULL|                  NULL|\n",
      "|   1107179603|2015-12-27 00:00:00|    1400.0|    NULL|       NULL|            CA|         201611.0|NULL|NISS|        PA|   WH| 3100 N BEACHWOOD DR| NULL|  54.0|         8058L|         PREF PARKING|       68.0|  99999.0|  99999.0|              NULL|             NULL|                  NULL|\n",
      "|   1107539823|2015-09-16 00:00:00|    2120.0|    NULL|       NULL|            CA|         201502.0|NULL|NISS|        PA| NULL|      BLAINE/11TH PL|1FB95|   1.0|        4000A1|   NO EVIDENCE OF REG|       50.0|  99999.0|  99999.0|              NULL|             NULL|                  NULL|\n",
      "|   1107539834|2015-09-16 00:00:00|    1045.0|    NULL|       NULL|            CA|             NULL|NULL|CHEV|        PA|   BK|  1246 S FIGUEROA ST| 1L20|   1.0|        8069AP|     NO STOP/STAND PM|       93.0|  99999.0|  99999.0|              NULL|             NULL|                  NULL|\n",
      "|   1107780811|2015-12-22 00:00:00|    1102.0|    NULL|       NULL|            CA|         201606.0|NULL|HOND|        PA|   BK|       PLATA/RAMPART|  2A1|   1.0|         8069B|           NO PARKING|       73.0|  99999.0|  99999.0|              NULL|             NULL|                  NULL|\n",
      "+-------------+-------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+--------------------+-----+------+--------------+---------------------+-----------+---------+---------+------------------+-----------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb2fe6d-bbbd-45ec-ad28-4fd9d0778997",
   "metadata": {},
   "source": [
    "### Question B.2 Print the schema for the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c65f9aa6-46f6-4f5f-8749-af09e90b5230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ticket number: string (nullable = true)\n",
      " |-- Issue Date: timestamp (nullable = true)\n",
      " |-- Issue time: double (nullable = true)\n",
      " |-- Meter Id: string (nullable = true)\n",
      " |-- Marked Time: double (nullable = true)\n",
      " |-- RP State Plate: string (nullable = true)\n",
      " |-- Plate Expiry Date: double (nullable = true)\n",
      " |-- VIN: string (nullable = true)\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Body Style: string (nullable = true)\n",
      " |-- Color: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Route: string (nullable = true)\n",
      " |-- Agency: double (nullable = true)\n",
      " |-- Violation code: string (nullable = true)\n",
      " |-- Violation Description: string (nullable = true)\n",
      " |-- Fine amount: double (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- Agency Description: string (nullable = true)\n",
      " |-- Color Description: string (nullable = true)\n",
      " |-- Body Style Description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema() #print schema of dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f47aff-f6a7-4adc-8287-5c2ca42f6471",
   "metadata": {},
   "source": [
    "### Question B.3 Count the number of rows in the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3232b8bf-7239-4338-b02f-0eda14e14055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13077724"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658fdbf2-3086-4037-ba15-fb9da29cd231",
   "metadata": {},
   "source": [
    "### Question B.4 Count the number of partitions in the underlying RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb7cbdba-77af-45ac-b88f-178822a331c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bda8137-469f-4f94-8df9-b46f9cdcd3af",
   "metadata": {},
   "source": [
    "### B.5 Drop the columns VIN, Latitude and Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bbeec3c-c88c-4572-b669-7c21e350cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_remove = [\"VIN\", \"Latitude\",\"Longitude\"]\n",
    "new_df = df.drop(*cols_to_remove) # deleting the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4cde25-23e5-4f3e-9a62-7fbe0b31f44c",
   "metadata": {},
   "source": [
    "### Question B.6 Find the maximum fine amount. How many fines have this amount?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6692b15e-9ebd-4656-a313-7578c1ee7add",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.withColumn('Fine amount', new_df['Fine amount'].cast('float').alias('Fine amount'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "684e6c90-8fa1-490f-9e23-e1d8526202ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100.0\n"
     ]
    }
   ],
   "source": [
    "max_value = new_df.agg({'Fine Amount':'max'}).collect()[0][0]\n",
    "print(max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12237874-e149-4639-9cbb-2e8738939084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum fine amount: 1100.0 and has been occured: 626 times\n"
     ]
    }
   ],
   "source": [
    "count_max = new_df.select('Fine amount').where(new_df['Fine amount'] == max_value).count()\n",
    "\n",
    "print(f'The maximum fine amount: {max_value} and has been occured: {count_max} times')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908d41a2-6fd7-44dc-bbaa-45591455f26a",
   "metadata": {},
   "source": [
    "### Question B.7 Show the top 20 most frequent vehicle makes, and their frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28472768-d914-4bcd-8148-b3bafda580e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:=================================================>      (14 + 2) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "|Make|  count|\n",
      "+----+-------+\n",
      "|TOYT|2150768|\n",
      "|HOND|1479996|\n",
      "|FORD|1116235|\n",
      "|NISS| 945133|\n",
      "|CHEV| 892676|\n",
      "| BMW| 603092|\n",
      "|MERZ| 543298|\n",
      "|VOLK| 432030|\n",
      "|HYUN| 404917|\n",
      "|DODG| 391686|\n",
      "|LEXS| 368420|\n",
      "| KIA| 328155|\n",
      "|JEEP| 316300|\n",
      "|AUDI| 255395|\n",
      "|MAZD| 242344|\n",
      "|OTHR| 205546|\n",
      "| GMC| 184889|\n",
      "|INFI| 174315|\n",
      "|CHRY| 159948|\n",
      "|SUBA| 154640|\n",
      "+----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "new_df.groupby('Make').count().orderBy('count', ascending=False).show() # find 20 most frequent car makes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738ebffa-2d63-43b7-9381-f209d9812dc2",
   "metadata": {},
   "source": [
    "### Question B.8 Let’s expand some abbreviations in the color column. Create a User Defined Function to create a new column, 'color long', mapping the original colors to their corresponding values in the dictionary below. If there is no key matching the original color, use the original color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c375b9b0-fa90-45c2-b2ee-be4f4f00f2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(dictionary): \n",
    "    return udf(lambda col: dictionary.get(col),StringType())\n",
    "\n",
    "COLORS = {\n",
    "'AL':'Aluminum', 'AM':'Amber', 'BG':'Beige', 'BK':'Black',\n",
    "'BL':'Blue', 'BN':'Brown', 'BR':'Brown', 'BZ':'Bronze',\n",
    "'CH':'Charcoal', 'DK':'Dark', 'GD':'Gold', 'GO':'Gold',\n",
    "'GN':'Green', 'GY':'Gray', 'GT':'Granite', 'IV':'Ivory',\n",
    "'LT':'Light', 'OL':'Olive', 'OR':'Orange', 'MR':'Maroon',\n",
    "'PK':'Pink', 'RD':'Red', 'RE':'Red', 'SI':'Silver', 'SL':'Silver',\n",
    "'SM':'Smoke', 'TN':'Tan', 'VT':'Violet', 'WT':'White', 'WH':'White',\n",
    "'YL':'Yellow', 'YE':'Yellow', 'UN':'Unknown'\n",
    "}\n",
    "\n",
    "new_df=new_df.withColumn('color long',translate(COLORS)('Color')) # creating new column with mapped colors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b37e5fa2-3150-4fd5-b3a0-0bec4542b259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ticket number: string (nullable = true)\n",
      " |-- Issue Date: timestamp (nullable = true)\n",
      " |-- Issue time: double (nullable = true)\n",
      " |-- Meter Id: string (nullable = true)\n",
      " |-- Marked Time: double (nullable = true)\n",
      " |-- RP State Plate: string (nullable = true)\n",
      " |-- Plate Expiry Date: double (nullable = true)\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Body Style: string (nullable = true)\n",
      " |-- Color: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Route: string (nullable = true)\n",
      " |-- Agency: double (nullable = true)\n",
      " |-- Violation code: string (nullable = true)\n",
      " |-- Violation Description: string (nullable = true)\n",
      " |-- Fine amount: float (nullable = true)\n",
      " |-- Agency Description: string (nullable = true)\n",
      " |-- Color Description: string (nullable = true)\n",
      " |-- Body Style Description: string (nullable = true)\n",
      " |-- color long: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4409e2-b4f0-454e-bac8-8e33a53d37ac",
   "metadata": {},
   "source": [
    "### Question B.9 Using this new column, what’s the most frequent colour value for Toyotas (TOYT)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e9f972c-b761-4c42-9e62-6efc6608f086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:====================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+\n",
      "|Make|mode(color long)|\n",
      "+----+----------------+\n",
      "|TOYT|            Gray|\n",
      "+----+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "new_df.groupby('Make').agg(mode('color long')).where(new_df['MAKE'] == 'TOYT').show() # finding frequent color in Toyota cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a49417e7-dc3f-43f6-9ff2-d2772cae0acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
